{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/train_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\"CreditScore\", \"Age\", \"Balance\", \"EstimatedSalary\"]\n",
    "categorical_features = [\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\"]\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False, drop='first')  \n",
    "\n",
    "# encoded_data = encoder.fit_transform(df[[\"Gender\", \"Geography\"]])\n",
    "# encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([\"Gender\", \"Geography\"]))\n",
    "\n",
    "# df = df.drop(columns=[\"Gender\", \"Geography\"]).reset_index(drop=True)\n",
    "# df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# df.head()  \n",
    "\n",
    "\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BalanceMinusSalary\"] = df[\"Balance\"] - df[\"EstimatedSalary\"]\n",
    "df[\"CreditScorePerBalance\"] = df[\"CreditScore\"] / (df[\"Balance\"] +1)\n",
    "# df[\"BalancePerTenure\"] = df[\"Balance\"] / (df[\"Tenure\"] +1)\n",
    "df[\"BalancePerSalary\"] = df[\"Balance\"] / (df[\"EstimatedSalary\"] +1)\n",
    "# df[\"BalanceToProdcutsRatio\"] = df[\"Balance\"] / (df[\"NumOfProducts\"] +1)\n",
    "# df[\"TenureToAge\"] = df[\"Tenure\"] / (df[\"Age\"] +1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CustomerId\", \"Surname\", \"ID\", \"HasCrCard\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_cols = [\"Age\", \"Balance\", \"CreditScorePerBalance\", \"CreditScorePerBalancePerTenure\", \"BalancePerTenure\", \"BalanceMinusSalary\"]\n",
    "# scaler = StandardScaler()\n",
    "# df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features & Target\n",
    "X = df.drop(columns=[\"Exited\"])\n",
    "y = df[\"Exited\"]\n",
    "\n",
    "# lgb_model = lgb.LGBMClassifier(verbose=-1)\n",
    "\n",
    "# lgb_model.fit(X, y)\n",
    "\n",
    "# # Get feature importance\n",
    "# lgb_importance = lgb_model.feature_importances_\n",
    "\n",
    "# # Create a DataFrame for plotting\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     \"Feature\": X.columns,\n",
    "#     \"LightGBM Importance\": lgb_importance\n",
    "# })\n",
    "\n",
    "# # Sort by importance\n",
    "# feature_importance_df = feature_importance_df.set_index(\"Feature\")\n",
    "# feature_importance_df = feature_importance_df.sort_values(by=\"LightGBM Importance\", ascending=False)\n",
    "\n",
    "# # Plot the feature importance\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# # sns.barplot(data=feature_importance_df, x=feature_importance_df.index, y=\"XGBoost Importance\", color=\"blue\", label=\"XGBoost\")\n",
    "# sns.barplot(data=feature_importance_df, x=feature_importance_df.index, y=\"LightGBM Importance\", color=\"red\", alpha=0.6, label=\"LightGBM\")\n",
    "\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title(\"Feature Importance for XGBoost & LightGBM\")\n",
    "# plt.xlabel(\"Features\")\n",
    "# plt.ylabel(\"Importance Score\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import lightgbm as lgb\n",
    "# import optuna\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Configuration du logger\n",
    "# logging.basicConfig(\n",
    "#     filename=\"optuna_lightgbm.log\",\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "#     datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "# )\n",
    "\n",
    "# def log(message):\n",
    "#     \"\"\" Fonction pour √©crire les logs dans le fichier et afficher en console (optionnel). \"\"\"\n",
    "#     logging.info(message)\n",
    "#     # print(message)  # Commente cette ligne si tu veux √©viter d'afficher dans la console.\n",
    "\n",
    "# Trouver le meilleur seuil pour maximiser F1 Score\n",
    "# def find_best_threshold(y_true, y_probs):\n",
    "#     thresholds = np.linspace(0.1, 0.9, 50)  # Tester 50 valeurs entre 0.1 et 0.9\n",
    "#     best_threshold = 0.5\n",
    "#     best_f1 = 0\n",
    "\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred = (y_probs >= threshold).astype(int)\n",
    "#         f1 = f1_score(y_true, y_pred)\n",
    "#         if f1 > best_f1:\n",
    "#             best_f1 = f1\n",
    "#             best_threshold = threshold\n",
    "\n",
    "#     return best_threshold, best_f1\n",
    "\n",
    "# # Optuna objective function\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"binary_logloss\",\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "#         \"boosting_type\": \"gbdt\",\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 70, 1000),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 250),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1),\n",
    "#         \"random_state\": 42,\n",
    "#         \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 5.0),\n",
    "#     }\n",
    "\n",
    "#     skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     f1_scores = []\n",
    "#     thresholds = []\n",
    "\n",
    "#     log(f\"\\nüîç Evaluating Trial {trial.number + 1} with Parameters: {params}\")\n",
    "\n",
    "#     for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#         model = lgb.LGBMClassifier(**params)\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         # Obtenir les probabilit√©s\n",
    "#         y_probs = model.predict_proba(X_val)[:, 1]  # Probabilit√© de la classe 1\n",
    "\n",
    "#         # Trouver le meilleur seuil pour maximiser F1\n",
    "#         best_threshold, best_f1 = find_best_threshold(y_val, y_probs)\n",
    "\n",
    "#         f1_scores.append(best_f1)\n",
    "#         thresholds.append(best_threshold)\n",
    "\n",
    "#         log(f\"üìä Fold {fold} - Best Threshold: {best_threshold:.2f} - F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "#     avg_f1 = np.mean(f1_scores)\n",
    "#     avg_threshold = np.mean(thresholds)\n",
    "\n",
    "#     log(f\"‚úÖ Trial {trial.number + 1} - Average F1 Score: {avg_f1:.4f} - Average Threshold: {avg_threshold:.2f}\\n\")\n",
    "\n",
    "#     return avg_f1\n",
    "\n",
    "# # Run Optuna study\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=500)\n",
    "\n",
    "# # Print best parameters\n",
    "# log(\"\\nüéØ Best Hyperparameters for LightGBM:\")\n",
    "# log(str(study.best_params))\n",
    "# log(f\"üíØ Best F1 Score: {study.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # S√©paration du dataset en Train (80%) et Test (20%)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# print(f\"‚úÖ Taille du Train Set: {X_train.shape[0]} √©chantillons\")\n",
    "# print(f\"‚úÖ Taille du Test Set: {X_test.shape[0]} √©chantillons\")\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Meilleurs hyperparam√®tres trouv√©s par Optuna\n",
    "# best_params = {\n",
    "#     \"objective\": \"binary\",\n",
    "#     \"metric\": \"binary_logloss\",\n",
    "#     \"learning_rate\": 0.01128001103820329,\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "#     \"n_estimators\": 959,\n",
    "#     \"num_leaves\": 82,\n",
    "#     \"subsample\": 0.9898192764991187,\n",
    "#     \"colsample_bytree\": 0.7150851486932676,\n",
    "#     \"random_state\": 42,\n",
    "#     \"scale_pos_weight\": 3.3682519378001508\n",
    "# }\n",
    "\n",
    "# # Entra√Æner le mod√®le final sur X_train\n",
    "# final_model = lgb.LGBMClassifier(**best_params)\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenir les probabilit√©s sur X_test\n",
    "# y_probs_test = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Trouver le meilleur seuil sur le TRAIN SET uniquement\n",
    "# best_threshold, _ = find_best_threshold(y_train, final_model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "# # Transformer les probabilit√©s en classes sur X_test avec ce seuil\n",
    "# y_pred_test = (y_probs_test >= best_threshold).astype(int)\n",
    "\n",
    "# print(f\"‚úÖ Meilleur Seuil de D√©cision: {best_threshold:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Affichage avec seaborn\n",
    "# plt.figure(figsize=(6,4))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Classe 0\", \"Classe 1\"], yticklabels=[\"Classe 0\", \"Classe 1\"])\n",
    "# plt.xlabel(\"Pr√©dictions\")\n",
    "# plt.ylabel(\"R√©el\")\n",
    "# plt.title(\"Matrice de Confusion sur Test Set\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calcul des m√©triques principales\n",
    "# accuracy = accuracy_score(y_test, y_pred_test)\n",
    "# precision = precision_score(y_test, y_pred_test)\n",
    "# recall = recall_score(y_test, y_pred_test)\n",
    "# f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# print(f\"‚úÖ Accuracy sur Test: {accuracy:.4f}\")\n",
    "# print(f\"üéØ Precision sur Test: {precision:.4f}\")\n",
    "# print(f\"‚ö° Recall sur Test: {recall:.4f}\")\n",
    "# print(f\"üíØ F1 Score sur Test: {f1:.4f}\")\n",
    "\n",
    "# # Rapport d√©taill√©\n",
    "# print(\"\\nüìä Classification Report sur Test Set:\")\n",
    "# print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,5))\n",
    "# sns.histplot(y_probs_test, bins=50, kde=True, color=\"blue\")\n",
    "# plt.axvline(best_threshold, color=\"red\", linestyle=\"dashed\", label=f\"Best Threshold = {best_threshold:.2f}\")\n",
    "# plt.xlabel(\"Probabilit√© de la Classe 1\")\n",
    "# plt.ylabel(\"Fr√©quence\")\n",
    "# plt.title(\"Distribution des Probabilit√©s sur Test Set\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Exited'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/4-classificationbankchurn-glxd70eG-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Exited'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convertir les features cat√©goriques\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_features:\n\u001b[0;32m---> 13\u001b[0m     df_test[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Feature Engineering\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBalanceMinusSalary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBalance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimatedSalary\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/4-classificationbankchurn-glxd70eG-py3.11/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/4-classificationbankchurn-glxd70eG-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Exited'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Charger le dataset test\n",
    "df_test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "# Convertir les features cat√©goriques\n",
    "for col in categorical_features:\n",
    "    df_test[col] = df_test[col].astype(\"category\")\n",
    "\n",
    "# Feature Engineering\n",
    "df_test[\"BalanceMinusSalary\"] = df_test[\"Balance\"] - df_test[\"EstimatedSalary\"]\n",
    "df_test[\"CreditScorePerBalance\"] = df_test[\"CreditScore\"] / (df_test[\"Balance\"] +1)\n",
    "df_test[\"BalancePerSalary\"] = df_test[\"Balance\"] / (df_test[\"EstimatedSalary\"] +1)\n",
    "\n",
    "# Sauvegarder l'ID pour la soumission\n",
    "df_ID_copy = df_test[\"ID\"].copy()\n",
    "\n",
    "# Nettoyage des colonnes inutiles\n",
    "df_test.drop(columns=[\"CustomerId\", \"Surname\", \"ID\", \"HasCrCard\"], inplace=True)\n",
    "\n",
    "# V√©rifier les colonnes manquantes ou en trop\n",
    "missing_cols = set(X.columns) - set(df_test.columns)\n",
    "if missing_cols:\n",
    "    print(f\"‚ö†Ô∏è Missing Columns in Test Set: {missing_cols}\")\n",
    "extra_cols = set(df_test.columns) - set(X.columns)\n",
    "if extra_cols:\n",
    "    print(f\"‚ö†Ô∏è Extra Columns in Test Set: {extra_cols}\")\n",
    "\n",
    "# Meilleurs hyperparam√®tres trouv√©s par Optuna\n",
    "best_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.01128001103820329,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 959,\n",
    "    \"num_leaves\": 82,\n",
    "    \"subsample\": 0.9898192764991187,\n",
    "    \"colsample_bytree\": 0.7150851486932676,\n",
    "    \"random_state\": 42,\n",
    "    \"scale_pos_weight\": 3.3682519378001508\n",
    "}\n",
    "\n",
    "# Entra√Æner le mod√®le sur toutes les donn√©es\n",
    "model = lgb.LGBMClassifier(**best_params)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenir les probabilit√©s sur l'ensemble d'entra√Ænement pour trouver le meilleur seuil\n",
    "y_probs_train = model.predict_proba(X)[:, 1]  # Probabilit√©s de la classe 1\n",
    "\n",
    "# Trouver le meilleur seuil pour maximiser le F1 Score\n",
    "def find_best_threshold(y_true, y_probs):\n",
    "    thresholds = np.linspace(0.1, 0.9, 50)  # Tester 50 seuils entre 0.1 et 0.9\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_probs >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Trouver le seuil optimal\n",
    "best_threshold, best_f1 = find_best_threshold(y, y_probs_train)\n",
    "print(f\"‚úÖ Meilleur Seuil Trouv√©: {best_threshold:.2f} (F1 Score: {best_f1:.4f})\")\n",
    "\n",
    "# Appliquer ce seuil aux pr√©dictions sur le test set\n",
    "y_probs_test = model.predict_proba(df_test)[:, 1]\n",
    "y_test_pred = (y_probs_test >= best_threshold).astype(int)\n",
    "\n",
    "# G√©n√©rer la soumission\n",
    "submission = pd.DataFrame({\"ID\": df_ID_copy, \"Exited\": y_test_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Submission file 'submission.csv' saved successfully!\")\n",
    "\n",
    "# Affichage de la distribution des probabilit√©s\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(y_probs_test, bins=50, kde=True, color=\"blue\")\n",
    "plt.axvline(best_threshold, color=\"red\", linestyle=\"dashed\", label=f\"Best Threshold = {best_threshold:.2f}\")\n",
    "plt.xlabel(\"Probabilit√© de la Classe 1\")\n",
    "plt.ylabel(\"Fr√©quence\")\n",
    "plt.title(\"Distribution des Probabilit√©s sur Test Set\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4-classificationbankchurn-glxd70eG-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
